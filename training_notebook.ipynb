{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:20:42.326139Z",
     "start_time": "2025-08-23T16:20:39.777101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from experiments.ModelLoader import load_vae_model\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !git clone https://github.com/akshitv2/VAE-latent-space-experiment.git\n",
    "# %cd VAE-latent-space-experiment\n",
    "# !git checkout celebA-ParamTweaking\n",
    "# !cp /content/drive/MyDrive/Datasets/img_align_celeba.zip /content/\n",
    "# !unzip /content/img_align_celeba.zip -d /content/dataset > /dev/null\n",
    "try:\n",
    "    import google.colab\n",
    "    running_in_colab = True\n",
    "except ImportError:\n",
    "    running_in_colab = False\n",
    "\n",
    "if running_in_colab:\n",
    "    dataset_dir = \"/content/dataset\"\n",
    "    out_dir: str = \"/content/drive/MyDrive/Temp/outputs\"\n",
    "    checkpoint_dir = \"/content/drive/MyDrive/Temp/checkpoints\"\n",
    "else:\n",
    "    dataset_dir = \"G:/Temp\"\n",
    "    out_dir: str = \"./outputs/\"\n",
    "    checkpoint_dir = \"./experiments/checkpoints\""
   ],
   "id": "394b36e86a25c140",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:20:45.212468Z",
     "start_time": "2025-08-23T16:20:42.326139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import GradScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from experiments.Checkpointing import save_checkpoint\n",
    "from models.VAE import VAE\n",
    "from modules.Losses import VAEVggLoss\n",
    "from modules.SaveOutputs import save_reconstructions\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dataset_dir: str = \"./data/raw\"\n",
    "out_dir: str = \"./outputs/\"\n",
    "batch_size: int = 64\n",
    "latent_dim: int = 256\n",
    "checkpoint_dir = \"./experiments/checkpoints\"\n",
    "# epochs: int = 10\n",
    "lr: float = 3e-4\n",
    "beta: float = 0.5\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # resize to 224x224\n",
    "    transforms.ToTensor()  # convert to tensor & scale to [0,1]\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"G:\\Temp\", transform=transform)\n",
    "train_test_split_var = 0.99\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(train_test_split_var*len(dataset)), len(dataset) - int(train_test_split_var*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "n_train = len(train_loader.dataset)\n",
    "print(\"Loaded datasets, number of samples: \", n_train)\n",
    "\n",
    "# Model & Optimizer\n",
    "scaler = GradScaler(device)\n",
    "model = VAE(latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "current_epoch = 1\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ],
   "id": "aFhAS1nbE4rr",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets, number of samples:  200573\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:20:45.353051Z",
     "start_time": "2025-08-23T16:20:45.229469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model = load_vae_model(checkpoint_path=\"./experiments/checkpoints/vae_checkpoint_epoch_16.pt\", device=device, latent_dim=latent_dim)\n",
    "# model.train()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "id": "beec498cecfc7e36",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T13:42:17.347843Z",
     "start_time": "2025-08-23T13:19:15.966133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "vgg_loss = VAEVggLoss(recon_weight=0.1, perc_weight=1.0, kl_weight=0.01, recon_loss_function = \"mse\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_total = running_recon = running_kld = running_perceptual =  0.0\n",
    "    progress_bar = tqdm(enumerate(train_loader, start=1), total=len(train_loader), desc=\"Training\")\n",
    "\n",
    "    for batch_idx, (x, _) in progress_bar:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits, mean, logvar = model(x)\n",
    "        loss, l1_loss, perc_loss, kl_loss = vgg_loss(logits, x, mean, logvar)\n",
    "        # loss, l1_loss, perc_loss, kl_loss = criterion(x_recon, x, mu, logvar)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        progress_bar.set_postfix(\n",
    "            loss=f\"{loss.item():.3f}\",\n",
    "            l1=f\"{l1_loss.item():.3f}\",\n",
    "            kld=f\"{kl_loss.item():.3f}\",\n",
    "            percep=f\"{perc_loss.item():.3f}\",\n",
    "\n",
    "        )\n",
    "        running_total += loss.item()\n",
    "        running_recon += l1_loss.item()\n",
    "        running_kld += kl_loss.item()\n",
    "        running_perceptual += perc_loss.item()\n",
    "    current_epoch += 1\n",
    "    print(\n",
    "        f\"Epoch {current_epoch:02d} | total: {running_total / n_train:.4f} | \"\n",
    "        f\"recon: {running_recon / n_train:.4f} | kld: {running_kld / n_train:.4f} | \"\n",
    "        f\"perceptual: {running_perceptual / n_train:.4f}\"\n",
    "    )\n",
    "    save_reconstructions(model=model, x=x, out_dir=out_dir, step = current_epoch, device=device, variant=\"\")\n",
    "    # save_reconstructions(model, x, out_dir, current_epoch, device)\n",
    "    if current_epoch % 10 == 0:\n",
    "        save_checkpoint(model, optimizer, current_epoch, checkpoint_dir)"
   ],
   "id": "f6f4708c3ac1f2ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3134/3134 [06:27<00:00,  8.08it/s, kld=60.538, l1=61.115, loss=233.405, percep=111.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | total: 3.7162 | recon: 0.9630 | kld: 0.9921 | perceptual: 1.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3134/3134 [08:07<00:00,  6.43it/s, kld=57.483, l1=63.732, loss=237.368, percep=116.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | total: 3.6910 | recon: 0.9967 | kld: 0.9503 | perceptual: 1.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3134/3134 [06:00<00:00,  8.69it/s, kld=58.957, l1=60.613, loss=232.041, percep=112.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | total: 3.6740 | recon: 1.0013 | kld: 0.9404 | perceptual: 1.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 921/3134 [01:45<04:14,  8.71it/s, kld=59.316, l1=65.984, loss=238.676, percep=113.376]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# loss, l1_loss, perc_loss, kl_loss = criterion(x_recon, x, mu, logvar)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 15\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     17\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mset_postfix(\n\u001B[0;32m     18\u001B[0m     loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     19\u001B[0m     l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml1_loss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     22\u001B[0m \n\u001B[0;32m     23\u001B[0m )\n",
      "File \u001B[1;32mD:\\Software\\Conda\\envs\\Torch\\lib\\site-packages\\torch\\amp\\grad_scaler.py:461\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    455\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    459\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 461\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_opt_step(optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    463\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32mD:\\Software\\Conda\\envs\\Torch\\lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    349\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    353\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    354\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 355\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moptimizer_state\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf_per_device\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    356\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32mD:\\Software\\Conda\\envs\\Torch\\lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    349\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    353\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    354\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 355\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    356\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
